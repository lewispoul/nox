{
  "rationale": "Introduce Redis-backed job persistence for cross-process state with Dramatiq worker, while retaining CI-friendly in-memory fallback. Tests use fakeredis; no external Redis required.",
  "changes": [
    {
      "path": "api/services/jobs_store.py",
      "action": "create_or_update",
      "content": "from __future__ import annotations\nimport os, json, time, uuid, threading\nfrom dataclasses import dataclass, asdict\nfrom typing import Optional, Dict, Any\n\n@dataclass\nclass Job:\n    id: str\n    state: str = \"queued\"  # queued|running|done|failed\n    result: Optional[dict] = None\n    error: Optional[str] = None\n    created_at: float = 0.0\n    updated_at: float = 0.0\n\n    def to_dict(self) -> dict:\n        d = asdict(self)\n        d.pop(\"created_at\", None)\n        d.pop(\"updated_at\", None)\n        return d\n\nclass InMemoryJobsStore:\n    def __init__(self) -> None:\n        self._jobs: Dict[str, Job] = {}\n        self._lock = threading.RLock()\n\n    def create(self) -> Job:\n        with self._lock:\n            now = time.time()\n            j = Job(id=str(uuid.uuid4()), created_at=now, updated_at=now)\n            self._jobs[j.id] = j\n            return j\n\n    def get(self, job_id: str) -> Optional[Job]:\n        with self._lock:\n            return self._jobs.get(job_id)\n\n    def set_state(self, job_id: str, state: str, *, result: Optional[dict]=None, error: Optional[str]=None) -> None:\n        with self._lock:\n            j = self._jobs[job_id]\n            j.state = state\n            j.result = result\n            j.error = error\n            j.updated_at = time.time()\n\nclass RedisJobsStore:\n    def __init__(self, redis_client) -> None:\n        self.r = redis_client\n        self.prefix = os.getenv(\"JOBS_PREFIX\", \"jobs:\")\n\n    def _key(self, job_id: str) -> str: return f\"{self.prefix}{job_id}\"\n\n    def create(self) -> Job:\n        job_id = str(uuid.uuid4())\n        now = time.time()\n        payload = {\n            \"id\": job_id,\n            \"state\": \"queued\",\n            \"result\": None,\n            \"error\": None,\n            \"created_at\": now,\n            \"updated_at\": now,\n        }\n        self.r.hset(self._key(job_id), mapping={k: json.dumps(v) for k,v in payload.items()})\n        return Job(**payload)\n\n    def get(self, job_id: str) -> Optional[Job]:\n        data = self.r.hgetall(self._key(job_id))\n        if not data:\n            return None\n        decoded = {k.decode(): json.loads(v) for k,v in data.items()}\n        return Job(**decoded)\n\n    def set_state(self, job_id: str, state: str, *, result: Optional[dict]=None, error: Optional[str]=None) -> None:\n        key = self._key(job_id)\n        now = time.time()\n        if result is None:\n            result_json = None\n        else:\n            result_json = result\n        self.r.hset(key, mapping={\n            \"state\": json.dumps(state),\n            \"result\": json.dumps(result_json),\n            \"error\": json.dumps(error),\n            \"updated_at\": json.dumps(now)\n        })\n\n# factory\n_store_singleton = None\n\ndef get_store():\n    global _store_singleton\n    if _store_singleton is not None:\n        return _store_singleton\n    REDIS_URL = os.getenv(\"REDIS_URL\")\n    if REDIS_URL:\n        import redis\n        client = redis.from_url(REDIS_URL)\n        _store_singleton = RedisJobsStore(client)\n    else:\n        _store_singleton = InMemoryJobsStore()\n    return _store_singleton\n"
    },
    {
      "path": "api/services/queue.py",
      "action": "create_or_update",
      "content": "from __future__ import annotations\nimport os, threading, time\nfrom typing import Dict, Any\nfrom .jobs_store import get_store\n\nREDIS_URL = os.getenv(\"REDIS_URL\")\n\n# Simple demo work; replace with real task kinds\ndef echo_worker(payload: Dict[str, Any]) -> Dict[str, Any]:\n    time.sleep(0.05)\n    return {\"echo\": payload}\n\ndef submit_job(kind: str, payload: Dict[str, Any]) -> str:\n    store = get_store()\n    job = store.create()\n    job_id = job.id\n\n    if REDIS_URL:\n        # Publish to Dramatiq actor; worker will update Redis-backed store\n        # We import inside to avoid dramatiq dep at import time in CI\n        from workers.jobs_worker import enqueue_job\n        enqueue_job.send(job_id, kind, payload)\n        return job_id\n\n    # Local thread mode for CI or dev without Redis\n    def _runner():\n        try:\n            store.set_state(job_id, \"running\")\n            if kind == \"echo\":\n                result = echo_worker(payload)\n            else:\n                result = {\"echo\": payload}\n            store.set_state(job_id, \"done\", result=result)\n        except Exception as e:  # noqa: BLE001\n            store.set_state(job_id, \"failed\", error=str(e))\n\n    threading.Thread(target=_runner, daemon=True).start()\n    return job_id\n"
    },
    {
      "path": "workers/jobs_worker.py",
      "action": "create_or_update",
      "content": "from __future__ import annotations\nimport os, time\nimport dramatiq\nfrom typing import Dict, Any\nfrom api.services.jobs_store import get_store\n\n# In worker process we always use the same get_store(), which will\n# resolve to RedisJobsStore if REDIS_URL is set.\n\n@dramatiq.actor\ndef enqueue_job(job_id: str, kind: str, payload: Dict[str, Any]):\n    store = get_store()\n    try:\n        store.set_state(job_id, \"running\")\n        # demo work\n        time.sleep(0.05)\n        if kind == \"echo\":\n            result = {\"echo\": payload}\n        else:\n            result = {\"echo\": payload}\n        store.set_state(job_id, \"done\", result=result)\n    except Exception as e:  # noqa: BLE001\n        store.set_state(job_id, \"failed\", error=str(e))\n"
    },
    {
      "path": "api/routes/jobs.py",
      "action": "create_or_update",
      "content": "from __future__ import annotations\nfrom fastapi import APIRouter, HTTPException\nfrom pydantic import BaseModel\nfrom typing import Any, Dict\nfrom api.services.queue import submit_job\nfrom api.services.jobs_store import get_store\n\nrouter = APIRouter()\n\nclass JobRequest(BaseModel):\n    kind: str = \"echo\"\n    payload: Dict[str, Any] = {}\n\n@router.post(\"/jobs\")\ndef create_job(req: JobRequest):\n    job_id = submit_job(req.kind, req.payload)\n    j = get_store().get(job_id)\n    return {\"id\": job_id, \"state\": j.state}\n\n@router.get(\"/jobs/{job_id}\")\ndef get_job(job_id: str):\n    j = get_store().get(job_id)\n    if not j:\n        raise HTTPException(404, detail=\"job not found\")\n    return j.to_dict()\n"
    },
    {
      "path": "tests/jobs/test_jobs_api.py",
      "action": "create_or_update",
      "content": "import asyncio, time, os\nimport pytest\nfrom fastapi import FastAPI\nfrom httpx import AsyncClient\nfrom httpx import ASGITransport\n\nfrom api.routes.jobs import router as jobs_router\n\n@pytest.mark.asyncio\nasync def test_jobs_echo_flow_local_mode(monkeypatch):\n    # Force local mode (no Redis)\n    monkeypatch.delenv(\"REDIS_URL\", raising=False)\n    app = FastAPI()\n    app.include_router(jobs_router)\n    transport = ASGITransport(app=app)\n    async with AsyncClient(transport=transport, base_url=\"http://test\") as client:\n        r = await client.post(\"/jobs\", json={\"kind\":\"echo\",\"payload\":{\"x\":1}})\n        assert r.status_code == 200\n        job = r.json(); job_id = job[\"id\"]\n        assert job[\"state\"] in {\"queued\",\"running\",\"done\"}\n        deadline = time.time() + 5\n        state = job[\"state\"]\n        while state not in {\"done\",\"failed\"} and time.time() < deadline:\n            await asyncio.sleep(0.05)\n            r2 = await client.get(f\"/jobs/{job_id}\")\n            state = r2.json()[\"state\"]\n        assert state == \"done\"\n\n@pytest.mark.asyncio\nasync def test_jobs_store_redis_via_fakeredis(monkeypatch):\n    # Validate Redis store behavior without real Redis\n    from api.services import jobs_store as js\n    import fakeredis, json\n    fake = fakeredis.FakeRedis()\n    store = js.RedisJobsStore(fake)\n    j = store.create()\n    assert j.state == \"queued\"\n    store.set_state(j.id, \"running\")\n    got = store.get(j.id)\n    assert got.state == \"running\"\n    store.set_state(j.id, \"done\", result={\"ok\": True})\n    got2 = store.get(j.id)\n    assert got2.state == \"done\" and got2.result == {\"ok\": True}\n"
    }
  ],
  "tests_to_add": ["tests/jobs/test_jobs_api.py"],
  "commands_to_run": ["pytest -k jobs_api -q"],
  "risks": ["Worker and API must share the same REDIS_URL; otherwise states won't update."],
  "expected_outputs": ["Local mode test passes without Redis. Redis store unit test passes via fakeredis. Cross-process works when worker runs with same REDIS_URL."]
}
